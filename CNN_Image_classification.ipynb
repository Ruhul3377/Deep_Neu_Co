{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 . Input Layer --CNN / Dense Layer / Convulated Layer \n",
    "\n",
    "<h4> i. Relu\n",
    "ii. Polling Layer\n",
    "iii. Upsamling\n",
    "  \n",
    "i. batchNormalization ii. Dropout  Layer \n",
    "\n",
    "2 . Hidden Layer --NN\n",
    "3. Output Layer --FCNN\n",
    "\n",
    "<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tensorflow\n",
    "2. Pytroch\n",
    "3. MaxNet\n",
    "\n",
    "1. Numpy \n",
    "2. Pandas\n",
    "3. pillow\n",
    "4. OpenCV\n",
    "5. Scikit Learn\n",
    "\n",
    "i. Plotly\n",
    "ii. matplotlib\n",
    "iii. Seaborn\n",
    "iv. D3.js\n",
    "\n",
    "vi . NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing Library<h4>\n",
    "\n",
    "```python\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "print(\"This is For Loop\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf \n",
    "import tensorflow as tf \n",
    "# This section for algebric analysis\n",
    "import numpy as np\n",
    "# This section for visualization \n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1000, 10)\n",
    "value = dict({\"product_price1\" : 10,\n",
    "\"product_price2\" : 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random : import random as rnd\n",
    "2. Numpy: import numpy.random as npr\n",
    "3. Tensorflow: import tensorflow.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(warnings.filterwarnings)\n",
    "\n",
    "class NeuralNetowrk:\n",
    "    def __init_(self, layers):\n",
    "        self.layers = layers\n",
    "        self.L = len(layers)\n",
    "\n",
    "        self.number_feature = layers[0]\n",
    "        self.number_class = layers[-1]\n",
    "\n",
    "        self.w = {}\n",
    "        self.b = {}\n",
    "\n",
    "        self.dw = {}\n",
    "        self.db = {}\n",
    "\n",
    "        self.setup()\n",
    "    def setup(self):\n",
    "        for i in range(i, self.L):\n",
    "            \n",
    "            self.W[i] = tf.variable(tf.random.normal(shape = (self.layers[i], self.layers[i-1])))\n",
    "            self.b[i] = tf.Variable(tf.random.normal(shape = (self.layers[i], 1))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way of create dtype\n",
    "\n",
    "1. dtype =\"float32\"\n",
    "2. dtype=np.float32\n",
    "3. dtype=tf.float32\n",
    "4. dtype=torch.float32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation \n",
    "\n",
    "class NeuralNetowrk(NeuralNetowrk):\n",
    "    def forwardPass(self, A):\n",
    "        A = tf.convert_to_tensor(A, dtype= float)\n",
    "        for i in range(1, self.L):\n",
    "            Z = tf.matmul(A, tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
    "            if i!= self.L-1:\n",
    "                A = tf.nn.relu(Z)\n",
    "            else:\n",
    "                A = Z\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this section for computing loss function and Upgrading the previous parameters\n",
    "class NeuralNetowrk(NeuralNetowrk):\n",
    "    def compute_loss(self, A, Y):\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(Y, A))\n",
    "    def upgrade_parameters(self, lr):\n",
    "        for j in range(1, self.L):\n",
    "            self.W[j].assign_sub(lr*self.dw[j])\n",
    "            self.b[j].assign_sub(lr*self.db[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 0 index ---> cats\n",
    "# 1 index ----> dogs\n",
    "v1=np.argmax([0.2, 0.9, 0.5])\n",
    "v2=np.argmax([0.12, 0.09])\n",
    "print(v1)\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetowrk(NeuralNetowrk):\n",
    "    def predict(self, x):\n",
    "        A = self.forwardPass(x)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis = 1)\n",
    "\n",
    "    def info(self):\n",
    "        num_params = 0\n",
    "        for i in range(1, self.L):\n",
    "            num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
    "            num_params += self .b[i].shape[0]\n",
    "\n",
    "        print(\"Number of Feature: {}\".format(self.number_feature))\n",
    "        print(\"Total Number of class is: {}\".format(self.number_class))\n",
    "\n",
    "        print(\"Hidden Layer information is: \")\n",
    "        for j in range (1, self.L -1):\n",
    "            print(\"Layer: {}, Units {}\". format(num_params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "class NeuralNetowrk(NeuralNetowrk):\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, step_per_epochs, batch_size, lr):\n",
    "        history = {\"val_loss\": [],\n",
    "        'train_loss':[],\n",
    "        'val_acc':[]}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Neur_Net')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301392c3b0eb06d6d45f21b27cd40d46634b624fb7988a05fbd688d0cc6eb63e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
